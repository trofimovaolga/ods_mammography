{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1645fca5",
   "metadata": {},
   "source": [
    "# Training a model using visualized tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c856a5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06e3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35aa5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import timm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "373205c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ab028",
   "metadata": {},
   "source": [
    "Custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd1c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_averaged_mean_absolute_error(y_true, y_pred):\n",
    "    labels = unique_labels(y_true, y_pred)\n",
    "    mae = []\n",
    "    for possible_class in labels:\n",
    "        indices = np.flatnonzero(y_true == possible_class)\n",
    "        mae.append(metrics.mean_absolute_error(y_true[indices], y_pred[indices],))\n",
    "\n",
    "    return np.sum(mae) / len(mae)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):    \n",
    "    y_true_arr = np.array(y_true)\n",
    "    y_pred_arr = np.array(y_pred)\n",
    "\n",
    "    if np.in1d(y_pred_arr, y_true_arr, invert=True).sum() > 0:\n",
    "        raise ValueError(\"There are non-existent labels in predictions\")\n",
    "\n",
    "    weights = np.array([1.0, 1.0, 1.5, 1.5, 1.5])\n",
    "    recall_multi = metrics.recall_score(y_true_arr, y_pred_arr, average=None)\n",
    "    weighted_accuracy = np.sum(np.multiply(recall_multi, weights)) / np.sum(weights)\n",
    "    mamae = macro_averaged_mean_absolute_error(y_true_arr, y_pred_arr)\n",
    "    return weighted_accuracy - 0.25 * mamae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefa2b80",
   "metadata": {},
   "source": [
    "Upload visualized tabular data prepared in ods_pic.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebfffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = pd.read_csv(\"data_train/targets_train.csv\", index_col=0)\n",
    "train_dir = 'img_tensors'\n",
    "test_dir = 'test_img_tensors'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b57159",
   "metadata": {},
   "source": [
    "Ð¡heck that the images can be rendered correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fd0962",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.load('{}/{}'.format(train_dir, os.listdir(train_dir)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd9feaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(image[26]);\n",
    "ax2.imshow(image[27]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34441240",
   "metadata": {},
   "source": [
    "Split the data to train (70%) and validation (30%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04e1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows, valid_rows = train_test_split(targets_train, \n",
    "                                          test_size=0.3, \n",
    "                                          random_state=24, \n",
    "                                          shuffle=True, \n",
    "                                          stratify=targets_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652263d",
   "metadata": {},
   "source": [
    "Make sure both sets contain a data of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7720fa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRads\n",
       "2         1693\n",
       "1         1043\n",
       "3           73\n",
       "4           31\n",
       "5            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rows.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9d42ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRads\n",
       "2         726\n",
       "1         447\n",
       "3          31\n",
       "4          13\n",
       "5           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rows.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c94cdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotations_file=None):\n",
    "        self.filenames = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.annotations_file = annotations_file\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.annotations_file is not None:\n",
    "            return len(self.annotations_file['BiRads'])\n",
    "        else:\n",
    "            return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.annotations_file is not None:         \n",
    "            filename = self.annotations_file.iloc[idx].name\n",
    "            label = self.annotations_file.loc[filename][0] - 1\n",
    "        else:\n",
    "            filename = self.filenames[idx][:-3]\n",
    "        \n",
    "        image = torch.load('{}/{}.pt'.format(self.img_dir, filename))\n",
    "        \n",
    "        if self.annotations_file is not None:            \n",
    "            return image, label\n",
    "        else:\n",
    "            return image, filename\n",
    "        \n",
    "    def get_labels(self):\n",
    "        return self.annotations_file[\"BiRads\"].to_numpy() - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca94ee",
   "metadata": {},
   "source": [
    "Define aug() function to create more data and avoid overfitting. By default it sets random 5 pixels to zero with 0.5 probability.\n",
    "\n",
    "It's only applied to channels starting from 3rd as first 3 channels are tissue_density_predicted, cancer_probability_predicted and laterality, which can't be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed125db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug(batch_tensor, p=0.5, num_changing=5):\n",
    "    pp = torch.rand(1)\n",
    "    if p >= pp:\n",
    "        zero_chan = ((batch_tensor.shape[1] - 3) * torch.rand(num_changing) + 3).long()\n",
    "        batch_tensor[:, zero_chan, :, :] = 0.0\n",
    "    return batch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7aa83ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(train_dir, train_rows)\n",
    "valid_data = CustomImageDataset(train_dir, valid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eddfa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "train_dataloader = DataLoader(train_data, \n",
    "                              sampler=ImbalancedDatasetSampler(train_data),\n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=2)\n",
    "valid_dataloader = DataLoader(valid_data, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86aa3ae",
   "metadata": {},
   "source": [
    "Using ResNet for training. The model inputs are images containing 46 channels, corresponding to 46 features. The number of outputs corresponds to the 5 Bi-Rads classes to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8d0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"resnet18\", num_classes=5, in_chans=46, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d16a3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb742fc1",
   "metadata": {},
   "source": [
    "The folowing is a training function. It saves the best (by custom_metrics) model as best_model.pt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ee813c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs):\n",
    "    best_metric = -1000.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                dataloader = train_dataloader\n",
    "                model.train()\n",
    "                scheduler.step()        \n",
    "            else:\n",
    "                dataloader = valid_dataloader\n",
    "                model.eval()\n",
    "\n",
    "            running_loss, running_acc = 0.0, 0.0\n",
    "            y_pred, y_true = [], []\n",
    "            \n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                if phase == 'train':\n",
    "                    inputs = aug(inputs, p=0.9, num_changing=20)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    preds = model(inputs)\n",
    "                    loss_value = loss(preds, labels)\n",
    "                    preds_class = preds.argmax(dim=1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss_value.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss_value.item()\n",
    "                running_acc += (preds_class == labels.data).float().mean()\n",
    "                \n",
    "                y_true.extend(labels.data.cpu().view(-1).numpy())\n",
    "                y_pred.extend(preds_class.cpu().numpy())\n",
    "                                \n",
    "            epoch_loss = running_loss / len(dataloader)\n",
    "            epoch_acc = running_acc / len(dataloader)\n",
    "            epoch_cust_metr = calculate_metrics(y_true, y_pred)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_accuracy_history.append(epoch_acc)\n",
    "                train_custom_metric_history.append(epoch_cust_metr)\n",
    "            else:\n",
    "                if epoch_cust_metr > best_metric:\n",
    "                    best_metric = epoch_cust_metr\n",
    "                    torch.save(model.state_dict(), \"/kaggle/working/best_model.pt\")\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_accuracy_history.append(epoch_acc)\n",
    "                val_custom_metric_history.append(epoch_cust_metr)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "            print('Custom metric: ', epoch_cust_metr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecee97b",
   "metadata": {},
   "source": [
    "The lists below will be filled out after training for further visualization of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82a97857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_history = []\n",
    "train_loss_history = []\n",
    "train_custom_metric_history = []\n",
    "val_accuracy_history = []\n",
    "val_loss_history = []\n",
    "val_custom_metric_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e989d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, loss, optimizer, scheduler, num_epochs=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "012e0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_history, label='train_loss')\n",
    "plt.plot(val_loss_history, label='val_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ee92240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy_history, label='train_accuracy')\n",
    "plt.plot(val_accuracy_history, label='val_accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f654fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_custom_metric_history, label='train_custom_metric')\n",
    "plt.plot(val_custom_metric_history, label='val_custom_metric')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2523952",
   "metadata": {},
   "source": [
    "Load the best model saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1231d847",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('best_model.pt'))\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3ccb7",
   "metadata": {},
   "source": [
    "After the model is trained, preparing submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b91ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CustomImageDataset(test_dir)\n",
    "test_dataloader = DataLoader(test_data, \n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=True, \n",
    "                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23314e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = []\n",
    "test_img = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for inputs, filename in tqdm(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(inputs)\n",
    "        preds_class = preds.argmax(dim=1)\n",
    "    test_predictions.append(preds_class.cpu().numpy())\n",
    "    test_img.extend(filename)\n",
    "test_predictions = np.concatenate(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(test_predictions + 1, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aab8a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame.from_dict({'id': test_img, 'BiRads': test_predictions + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8857f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BiRads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0a0fafbb-741c-4ce4-8858-869fc1962f7d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a3bdee6-7be6-401f-93a5-62060fa6d7d1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0a70bed8-2839-4a1e-beb1-783fc3e61af8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a8e4353-f070-46fd-99b8-8f9dd78ee4fa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0a673d69-7ff1-42c8-8063-ea01eb905d38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  BiRads\n",
       "0  0a0fafbb-741c-4ce4-8858-869fc1962f7d       1\n",
       "1  0a3bdee6-7be6-401f-93a5-62060fa6d7d1       3\n",
       "2  0a70bed8-2839-4a1e-beb1-783fc3e61af8       3\n",
       "3  0a8e4353-f070-46fd-99b8-8f9dd78ee4fa       1\n",
       "4  0a673d69-7ff1-42c8-8063-ea01eb905d38       4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee6727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc8367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
